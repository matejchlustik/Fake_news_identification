{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"embedded_datasets/Word2Vec/Word2Vec_Embedded_Dataset.csv\")\n",
    "\n",
    "df[\"article_embedding\"] = df[\"article_embedding\"].apply(ast.literal_eval)\n",
    "\n",
    "df = df[[\"article_embedding\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generalization = pd.read_csv(\n",
    "    \"embedded_datasets/Word2Vec/Word2Vec_Embedded_Generalization_Dataset.csv\"\n",
    ")\n",
    "df_generalization[\"article_embedding\"] = df_generalization[\"article_embedding\"].apply(\n",
    "    ast.literal_eval\n",
    ")\n",
    "df_generalization = df_generalization[[\"article_embedding\", \"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df[\"article_embedding\"].tolist())\n",
    "y = df[\"label\"]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'bootstrap': False, 'criterion': 'log_loss', 'max_depth': 19, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 14, 'n_estimators': 541}\n",
      "Best Cross-Validated Accuracy: 0.8360812633321756\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define hyperparameter distributions\n",
    "param_distributions = {\n",
    "    \"n_estimators\": randint(300, 700),\n",
    "    \"max_depth\": randint(5, 20),\n",
    "    \"min_samples_split\": randint(2, 20),\n",
    "    \"min_samples_leaf\": randint(1, 20),\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "}\n",
    "\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=4,\n",
    ")\n",
    "\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", random_search_rf.best_params_)\n",
    "print(\"Best Cross-Validated Accuracy:\", random_search_rf.best_score_)\n",
    "\n",
    "best_rf = random_search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(best_rf, \"Word2VecModels/random_forest_model2.joblib\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81      6110\n",
      "           1       0.83      0.89      0.86      7750\n",
      "\n",
      "    accuracy                           0.84     13860\n",
      "   macro avg       0.84      0.83      0.83     13860\n",
      "weighted avg       0.84      0.84      0.84     13860\n",
      "\n",
      "[[4702 1408]\n",
      " [ 849 6901]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_generalization = np.array(\n",
    "    df_generalization[\"article_embedding\"].tolist()\n",
    ")  # Convert list of embeddings to a 2D array\n",
    "y_generalization = df_generalization[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_generalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.73      3037\n",
      "           1       0.74      0.60      0.66      2952\n",
      "\n",
      "    accuracy                           0.70      5989\n",
      "   macro avg       0.71      0.70      0.69      5989\n",
      "weighted avg       0.70      0.70      0.70      5989\n",
      "\n",
      "[[2412  625]\n",
      " [1182 1770]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_generalization, y_pred))\n",
    "print(confusion_matrix(y_generalization, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df[\"article_embedding\"].tolist())\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matej\\SKOLA\\Diplomovka\\Code\\EmbeddingModels\\.venv\\Lib\\site-packages\\numpy\\ma\\core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 0.9, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 500, 'subsample': 0.9}\n",
      "Best Log Loss Score: 0.2735121429205592\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    device=\"cuda\",\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"n_estimators\": [300, 500],\n",
    "    \"subsample\": [0.8, 0.9],\n",
    "    \"colsample_bytree\": [0.8, 0.9],\n",
    "    \"gamma\": [0, 0.1],\n",
    "    \"min_child_weight\": [1, 3, 5],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_log_loss\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=3,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Log Loss Score:\", -best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(best_model, \"xgboost_new_model.joblib\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.86      6169\n",
      "           1       0.87      0.90      0.89      7691\n",
      "\n",
      "    accuracy                           0.87     13860\n",
      "   macro avg       0.87      0.87      0.87     13860\n",
      "weighted avg       0.87      0.87      0.87     13860\n",
      "\n",
      "[[5178  991]\n",
      " [ 755 6936]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matej\\SKOLA\\Diplomovka\\Code\\EmbeddingModels\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:52:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df[\"article_embedding\"].tolist())\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best Accuracy: 0.8819540198491341\n",
      "Test Accuracy: 0.8859307359307359\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC()\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": [0.1, 1, 10],\n",
    "    \"kernel\": [\"linear\", \"rbf\"],\n",
    "    \"gamma\": [\"scale\", \"auto\", 0.1],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svm_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=4,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_score)\n",
    "\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87      6169\n",
      "           1       0.89      0.90      0.90      7691\n",
      "\n",
      "    accuracy                           0.89     13860\n",
      "   macro avg       0.89      0.88      0.88     13860\n",
      "weighted avg       0.89      0.89      0.89     13860\n",
      "\n",
      "[[5319  850]\n",
      " [ 731 6960]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(best_model, \"Word2VecModels/svm_model.joblib\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"embedded_datasets/Word2Vec/Word2Vec_Embedded_Generalization_Dataset.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"article_embedding\"] = df[\"article_embedding\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>article_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.04956003278493881, 0.03957546502351761, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.05896731838583946, 0.042814381420612335, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.0299783106893301, 0.05943034961819649, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.05501393973827362, 0.025511030107736588, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.04850117489695549, 0.05607370659708977, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.008780215866863728, 0.029638497158885002, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5985</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.023696385324001312, 0.042197830975055695, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5986</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.03499678894877434, 0.04463842883706093, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5987</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.02768431045114994, 0.07343021780252457, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5988</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.05949508398771286, 0.05742717161774635, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5989 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                  article_embedding\n",
       "0         0  [0.04956003278493881, 0.03957546502351761, 0.0...\n",
       "1         0  [0.05896731838583946, 0.042814381420612335, 0....\n",
       "2         1  [0.0299783106893301, 0.05943034961819649, 0.06...\n",
       "3         0  [0.05501393973827362, 0.025511030107736588, 0....\n",
       "4         1  [0.04850117489695549, 0.05607370659708977, 0.0...\n",
       "...     ...                                                ...\n",
       "5984      1  [0.008780215866863728, 0.029638497158885002, 0...\n",
       "5985      0  [0.023696385324001312, 0.042197830975055695, 0...\n",
       "5986      0  [0.03499678894877434, 0.04463842883706093, 0.0...\n",
       "5987      1  [0.02768431045114994, 0.07343021780252457, 0.0...\n",
       "5988      1  [0.05949508398771286, 0.05742717161774635, 0.0...\n",
       "\n",
       "[5989 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_gen = np.array(df[\"article_embedding\"].tolist())\n",
    "\n",
    "\n",
    "y_gen = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the model from the file\n",
    "model = joblib.load(\"Word2VecModels/random_forest_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=False, max_depth=24, min_samples_leaf=3,\n",
       "                       n_estimators=912, random_state=42)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73      3037\n",
      "           1       0.74      0.61      0.67      2952\n",
      "\n",
      "    accuracy                           0.70      5989\n",
      "   macro avg       0.71      0.70      0.70      5989\n",
      "weighted avg       0.71      0.70      0.70      5989\n",
      "\n",
      "[[2413  624]\n",
      " [1146 1806]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_gen, y_pred))\n",
    "print(confusion_matrix(y_gen, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.95      0.82      3127\n",
      "           1       0.92      0.64      0.75      3171\n",
      "\n",
      "    accuracy                           0.79      6298\n",
      "   macro avg       0.82      0.79      0.79      6298\n",
      "weighted avg       0.82      0.79      0.79      6298\n",
      "\n",
      "[[2961  166]\n",
      " [1152 2019]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_gen, y_pred))\n",
    "print(confusion_matrix(y_gen, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"embedded_datasets/Word2Vec/Word2Vec_Embedded_Dataset.csv\")\n",
    "\n",
    "df[\"article_embedding\"] = df[\"article_embedding\"].apply(ast.literal_eval)\n",
    "\n",
    "df = df[[\"article_embedding\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generalization = pd.read_csv(\n",
    "    \"embedded_datasets/Word2Vec/Word2Vec_Embedded_Generalization_Dataset.csv\"\n",
    ")\n",
    "df_generalization[\"article_embedding\"] = df_generalization[\"article_embedding\"].apply(\n",
    "    ast.literal_eval\n",
    ")\n",
    "df_generalization = df_generalization[[\"article_embedding\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df[\"article_embedding\"].tolist())\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gen = np.array(df_generalization[\"article_embedding\"].tolist())\n",
    "y_gen = df_generalization[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"Word2VecModels/random_forest_model2.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8414\n",
      "Precision: 0.8353\n",
      "Recall: 0.8896\n",
      "F1 Score: 0.8616\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.81      6169\n",
      "           1       0.84      0.89      0.86      7691\n",
      "\n",
      "    accuracy                           0.84     13860\n",
      "   macro avg       0.84      0.84      0.84     13860\n",
      "weighted avg       0.84      0.84      0.84     13860\n",
      "\n",
      "[[4820 1349]\n",
      " [ 849 6842]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6978\n",
      "Precision: 0.7361\n",
      "Recall: 0.6030\n",
      "F1 Score: 0.6629\n"
     ]
    }
   ],
   "source": [
    "y_pred_gen = model.predict(X_gen)\n",
    "\n",
    "accuracy = accuracy_score(y_gen, y_pred_gen)\n",
    "precision = precision_score(y_gen, y_pred_gen)\n",
    "recall = recall_score(y_gen, y_pred_gen)\n",
    "f1 = f1_score(y_gen, y_pred_gen)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.73      3037\n",
      "           1       0.74      0.60      0.66      2952\n",
      "\n",
      "    accuracy                           0.70      5989\n",
      "   macro avg       0.70      0.70      0.69      5989\n",
      "weighted avg       0.70      0.70      0.69      5989\n",
      "\n",
      "[[2399  638]\n",
      " [1172 1780]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_gen, y_pred_gen))\n",
    "print(confusion_matrix(y_gen, y_pred_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
